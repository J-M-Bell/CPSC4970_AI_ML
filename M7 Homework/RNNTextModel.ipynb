{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934c0083",
   "metadata": {},
   "source": [
    "<h1><strong><u>RNN Text Model</u></strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from keras import Input, activations\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import SimpleRNN, Dense, LSTM, Dropout, Embedding\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831ea7e",
   "metadata": {},
   "source": [
    "<h2><strong><u>Data Preprocessing Methods</u></strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14326f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    new_text = text.lower() #lowercase\n",
    "    new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "    text_array = word_tokenize(new_text) #tokenize\n",
    "    return text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51571cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"Given a list of words, I encode it word by word with each word being a sample). \n",
    "    I return the result and the encoder.\"\"\"\n",
    "    new_text = text.lower() #lowercase\n",
    "    new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "    text_array = word_tokenize(new_text) #tokenize\n",
    "    info(\"Encoding inputs...\")\n",
    "    debug(f\"{text_array}\")\n",
    "    encoder = OrdinalEncoder()\n",
    "    #result = encoder.fit_transform(text)\n",
    "    result = encoder.fit_transform(np.reshape(text_array, (len(text_array), 1)))\n",
    "    # info(\"Number of input characters:\", len(encoder.categories_[0]))\n",
    "    # debug(\"Input categories:\", encoder.categories_[0])\n",
    "    # info(f\"{result.shape=}\")\n",
    "    # debug(result)\n",
    "    #print(result.shape)\n",
    "    return result, encoder\n",
    "\n",
    "\n",
    "# encoded_array, encoder = encode_text(text)\n",
    "# features, targets = time_delayed(encoded_array, 5)\n",
    "# print(\"Features:\")\n",
    "# print(features.shape[1:])\n",
    "# print(\"Targets:\")\n",
    "# print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1342e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_value = max(encoded_array)\n",
    "# print(max_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14cd62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(encoded_array.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ff6e1",
   "metadata": {},
   "source": [
    "<h2><u>RNN Class</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af66067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_DEBUG = False\n",
    "PRINT_INFO = True\n",
    "\n",
    "\n",
    "def debug(*args):\n",
    "    if PRINT_DEBUG:\n",
    "        print(*args)\n",
    "\n",
    "\n",
    "def info(*args):\n",
    "    if PRINT_INFO:\n",
    "        print(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20303049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delayed(seq, delay):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for target_index in range(delay, len(seq)):\n",
    "        features.append(seq[target_index - delay:target_index])\n",
    "        targets.append(seq[target_index])\n",
    "    return np.array(features), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abecf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this will need to be modified to handle words instead of letters\n",
    "# def encode_sequence(sequence):\n",
    "#     \"\"\"Given a string, I encode it letter by letter (each letter is a sample). I return the\n",
    "#     result and the encoder.\"\"\"\n",
    "#     info(\"Encoding inputs...\")\n",
    "#     debug(f\"{sequence}\")\n",
    "#     encoder = OrdinalEncoder(sparse=False)\n",
    "#     result = encoder.fit_transform(np.reshape(sequence, (len(sequence), 1)))\n",
    "#     info(\"Number of input characters:\", len(encoder.categories_[0]))\n",
    "#     debug(\"Input categories:\", encoder.categories_[0])\n",
    "#     info(f\"{result.shape=}\")\n",
    "#     debug(result)\n",
    "#     return result, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTextModel:\n",
    "    def __init__(self, training_string, delay_length=100):\n",
    "        encoded_training_data, self.encoder = encode_text(training_string)\n",
    "        self.time_steps = delay_length\n",
    "        max_vocabulary_size = len(set(encoded_training_data.flatten()))\n",
    "        info(\"Number of distinct words:\", max_vocabulary_size)\n",
    "        debug(\"encoded_training_data:\", encoded_training_data)\n",
    "        self.X_delayed, self.y_delayed = time_delayed(encoded_training_data, self.time_steps)\n",
    "        print(self.X_delayed.shape)\n",
    "        self.model = self.create_model(max_vocabulary_size, self.X_delayed.shape, self.y_delayed.shape)\n",
    "\n",
    "    #figure out shape issues to see which values to use for embedding layer\n",
    "    def create_model(self, max_vocabulary_size, input_shape, output_shape, delay_length=100):\n",
    "        info(\"Creating model...\")\n",
    "        info(\"Input shape:\", input_shape[1:])\n",
    "        model = Sequential(\n",
    "            [Input(shape=input_shape[1:]),\n",
    "            Embedding(input_dim=max_vocabulary_size, output_dim=64, input_length=delay_length),\n",
    "            LSTM(256, return_sequences=True, activation=activations.tanh),\n",
    "            Dropout(0.2),\n",
    "            LSTM(256, activation=activations.tanh),\n",
    "            Dropout(0.2),\n",
    "            Dense(output_shape[1], activation=activations.softmax)]\n",
    "        )\n",
    "        model.summary()\n",
    "        model.compile(optimizer=\"adam\", loss=CategoricalCrossentropy(), metrics=[\"categorical_accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    def encode_input_string(self, string):\n",
    "        encoded_input_array = encode_text(string)\n",
    "        return encoded_input_array\n",
    "    \n",
    "    def fit(self, prefix, epochs=2):\n",
    "        info(\"Fitting...\")\n",
    "        callbacks = []\n",
    "        if prefix is not None:\n",
    "            checkpoint = ModelCheckpoint(prefix + \"-{epoch:03d}-{loss:.4f}.hdf5\", monitor='loss', verbose=1,\n",
    "                                         save_best_only=True, mode='min')\n",
    "            callbacks = [checkpoint]\n",
    "        self.model.fit(self.X_delayed, self.y_delayed, epochs=epochs, verbose=True, callbacks=callbacks, batch_size=1000)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        info(f\"Loading weights from {filename}...\")\n",
    "        self.model.load_weights(filename)\n",
    "    \n",
    "    def predict_from_seed(self, seed, prediction_count):\n",
    "        info(\"Predicting output sequence...\")\n",
    "        result = seed\n",
    "        new_seed = seed\n",
    "        for i in range(prediction_count):\n",
    "            inp = self.encode_input_string(new_seed)\n",
    "            debug(f\"{inp=}\")\n",
    "            p = self.encoder.inverse_transform(self.model.predict(inp))\n",
    "            debug(f\"{p=}\")\n",
    "            print(p.shape)\n",
    "            print(f\"Predicted word: {p[0][0]}\")\n",
    "            result += p[0][0]\n",
    "            new_seed = result[-len(seed):]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71ca0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(text, seed):\n",
    "    rnn_model = RNNTextModel(text)\n",
    "    rnn_model.fit(prefix=\"rnn_text_model\", epochs=50)\n",
    "    output = rnn_model.predict_from_seed(seed, 100)\n",
    "    print(f\"Generated text: {seed} {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9deb6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"./the_sunken_world.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'your_file.txt' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15213c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = '''For strategic reasons, this fact was not divulged\n",
    "until much later, and for strategic reasons it was not made known\n",
    "that the missing submarine was of a new and previously untried type;\n",
    "but'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47d0adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding inputs...\n",
      "Number of distinct words: 2131\n",
      "(7574, 100, 1)\n",
      "Creating model...\n",
      "Input shape: 2131\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(text, seed)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m(text, seed):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     rnn_model = \u001b[43mRNNTextModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     rnn_model.fit(prefix=\u001b[33m\"\u001b[39m\u001b[33mrnn_text_model\u001b[39m\u001b[33m\"\u001b[39m, epochs=\u001b[32m50\u001b[39m)\n\u001b[32m      4\u001b[39m     output = rnn_model.predict_from_seed(seed, \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mRNNTextModel.__init__\u001b[39m\u001b[34m(self, training_string, delay_length)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.X_delayed, \u001b[38;5;28mself\u001b[39m.y_delayed = time_delayed(encoded_training_data, \u001b[38;5;28mself\u001b[39m.time_steps)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m.X_delayed.shape)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_vocabulary_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_delayed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_delayed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mRNNTextModel.create_model\u001b[39m\u001b[34m(max_vocabulary_size, input_shape, output_shape, delay_length)\u001b[39m\n\u001b[32m     14\u001b[39m info(\u001b[33m\"\u001b[39m\u001b[33mCreating model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m info(\u001b[33m\"\u001b[39m\u001b[33mInput shape:\u001b[39m\u001b[33m\"\u001b[39m, input_shape)\n\u001b[32m     16\u001b[39m model = Sequential(\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     [Input(shape=\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m),\n\u001b[32m     18\u001b[39m     Embedding(input_dim=max_vocabulary_size, output_dim=\u001b[32m64\u001b[39m, input_length=delay_length),\n\u001b[32m     19\u001b[39m     LSTM(\u001b[32m256\u001b[39m, return_sequences=\u001b[38;5;28;01mTrue\u001b[39;00m, activation=activations.tanh),\n\u001b[32m     20\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     21\u001b[39m     LSTM(\u001b[32m256\u001b[39m, activation=activations.tanh),\n\u001b[32m     22\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     23\u001b[39m     Dense(output_shape[\u001b[32m1\u001b[39m], activation=activations.softmax)]\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m model.summary()\n\u001b[32m     26\u001b[39m model.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, loss=CategoricalCrossentropy(), metrics=[\u001b[33m\"\u001b[39m\u001b[33mcategorical_accuracy\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "main(text, seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
