{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1190e1d",
   "metadata": {},
   "source": [
    "<h1><strong><u>K-Nearest Neighbors Model Selection</u></strong></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV, validation_curve\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB, CategoricalNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce4c8e",
   "metadata": {},
   "source": [
    "<h2><u>Data Loading</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"title\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51344d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting text files\n",
    "titles = []\n",
    "targets = []\n",
    "file_path_dict = {'clickbait': './clickbait_data.txt', 'non clickbait': './non_clickbait_data.txt'}\n",
    "for key, value in file_path_dict.items():\n",
    "    with open(value, 'r') as file:\n",
    "        for line_number, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                titles.append(line)\n",
    "                targets.append(key)\n",
    "data_dict = {\"title\": titles, \"target\": targets}\n",
    "df = pd.DataFrame(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6efdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Percent KatyCat Are You</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rwandan army officer sentenced to 25 years for...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17 Times Kourtney Kardashian Shut Down Her Own...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada's Conservatives launch new ad campaign</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17 Makeup Facts That Show Humans Will Do Anyth...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>Andrew Garfield Has Transformed From One \"Harr...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>Work on Lehman Brothers’ rescue to continue ov...</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>13 Beautifully Honest Valentine's Cards For Pe...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>17 Awkward Moments When You're A Jew On Christmas</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>Bowler Brett Lee to miss first Ashes Test</td>\n",
       "      <td>non clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         target\n",
       "0                           What Percent KatyCat Are You      clickbait\n",
       "1      Rwandan army officer sentenced to 25 years for...  non clickbait\n",
       "2      17 Times Kourtney Kardashian Shut Down Her Own...      clickbait\n",
       "3          Canada's Conservatives launch new ad campaign  non clickbait\n",
       "4      17 Makeup Facts That Show Humans Will Do Anyth...      clickbait\n",
       "...                                                  ...            ...\n",
       "31995  Andrew Garfield Has Transformed From One \"Harr...      clickbait\n",
       "31996  Work on Lehman Brothers’ rescue to continue ov...  non clickbait\n",
       "31997  13 Beautifully Honest Valentine's Cards For Pe...      clickbait\n",
       "31998  17 Awkward Moments When You're A Jew On Christmas      clickbait\n",
       "31999          Bowler Brett Lee to miss first Ashes Test  non clickbait\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.sample(frac=1).reset_index(drop=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb21c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data[\"title\"]\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "display(X_train.shape) \n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73083076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        import re\n",
    "        en_stopwords = stopwords.words('english')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        new_text = text.lower() #lowercase\n",
    "\n",
    "        new_text = re.sub(r\"([^\\w\\s])\", \"\", new_text) #remove punctuation\n",
    "\n",
    "        for word in new_text.split(): #remove stopwords\n",
    "            if word in en_stopwords:\n",
    "                new_text = new_text.replace(word, \"\")\n",
    "        \n",
    "        new_text = word_tokenize(new_text) #tokenize\n",
    "\n",
    "        new_text = [lemmatizer.lemmatize(token) for token in new_text] #lemmatize\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080962ac",
   "metadata": {},
   "source": [
    "<h2><strong><u>Naive Bayes Model Selection</u></strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865777d",
   "metadata": {},
   "source": [
    "I believe that the <strong>BernoulliNB</strong> model is the best Naive Bayes model for this dataset because it is designed for binary/boolean features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28262824",
   "metadata": {},
   "source": [
    "<h3><u>Validation Curves</u></h3>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
